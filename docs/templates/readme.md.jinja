# Faux Data

[![PyPI Latest Release](https://img.shields.io/pypi/v/faux-data.svg)](https://pypi.org/project/faux-data/)
![Tests](https://github.com/jack-tee/faux-data/actions/workflows/Tests.yaml/badge.svg)

Faux Data is a library for generating data using configuration files.

The configuration files are called templates. Within a template, `columns` define the structure of the data and `targets` define where to load the data.

The main aims of Faux Data are:
- Make it easy to generate schematically correct datasets
- Provide easy integration with cloud services specifically on the Google Cloud Platform
- Support serverless generation of data e.g. using a Cloud Function invocation to generate data

Faux Data was originally a Python port of the scala application [dunnhumby/data-faker](https://github.com/dunnhumby/data-faker), but has evolved from there. The templates are still similar but are not directly compatible.

## Contents

- [Quick Start](#quick-start)
- [Columns](#columns)
  - {% for name in column_docs.columns %}[{{ name }}](#{{ name | lower }}){{ ", " if not loop.last else "" }}{% endfor %}
- [Targets](#targets)
  - {% for target in targets %}[{{ target[0] }}](#{{ target[0] | lower }}){{ ", " if not loop.last else "" }}{% endfor %}
- [Usage](#usage)
- [Concepts](#concepts)

## Quick Start

### Install

Install faux-data locally via pip

`> pip install faux-data`

check the install has been successful with

`> faux --help`


### A Simple Template

Create a file `mytable.yaml` with the following contents:

```
tables:
  - name: mytable
    rows: 100
    targets: []
    columns:
      - name: id
        column_type: Sequential
        data_type: Int
        start: 1
        step: 1
    
      - name: event_time
        column_type: Random
        data_type: Timestamp
        min: '{{ '{{ start }}' }}'
        max: '{{ '{{ end }}' }}'
```

You can render this template with:

```
> faux render mytable.yaml

====================== Rendered Template =======================
tables:
  - name: mytable
    rows: 100
    targets: []
    columns:
      - name: id
        column_type: Sequential
        data_type: Int
        start: 1
        step: 1
    
      - name: event_time
        column_type: Random
        data_type: Timestamp
        min: '2022-05-20 00:00:00'
        max: '2022-05-21 00:00:00'
```

Notice that {{ '{{ start }}' }} and {{ '{{ end }}' }} are replaced with start and end dates automatically. Start and end are built-in variables that you can use in templates.
Start defaults to the start of yesterday and end defaults to the end of yesterday.

If you run:

```
> faux render mytable.yaml --start 2022-06-10

====================== Rendered Template =======================
    
    ...

      - name: event_time
        column_type: Random
        data_type: Timestamp
        min: '2022-06-10 00:00:00'
        max: '2022-06-11 00:00:00'
      
```

Notice now that {{ '{{ start }}' }} and {{ '{{ end }}' }} are now based on the provided `--start` value.


The two columns we have added so far use the long form syntax, which can get a bit verbose, there's a shorter syntax that can be used as well. Lets add another column using the more concise syntax
add the following column to your file.
```
      - col: currency Selection String
        values:
          - USD
          - GBP
          - EUR
```

Now let's test that the data is generated correctly run the following to see a sample of generated data.

```
> faux sample mytable.yaml

Table: mytable
Sample:
   id              event_time currency
0   1 2022-05-20 14:47:56.866      EUR
1   2 2022-05-20 09:24:11.971      GBP
2   3 2022-05-20 14:11:00.144      GBP
3   4 2022-05-20 22:32:35.579      EUR
4   5 2022-05-20 00:31:02.248      GBP

Schema:
id                     Int64
event_time    datetime64[ns]
currency              string
dtype: object
``` 

### Running the Template
In order for the data to be useful we need to load it somewhere, let's add a target to load the data to bigquery.

Add the following into the template replacing `targets: []`

```
    targets: 
      - target: BigQuery
        dataset: mydataset
        table: mytable
```

> To run this step you will need a google cloud project and to have your environment set up with google application credentials. 

Then run 

`> faux run mytable.yaml`

This will create a dataset in your google cloud project named mydataset and a table within called mytable and will load 100 rows of data to it.

## Columns

faux-data templates support the following `column_type:`s:

{% for name, column in column_docs.columns.items() -%}
- **[{{ name }}](#{{ name | lower }}) - {{ column.title }}**
   
   {% if column.examples %}_Examples: {% for example in column.examples %}[{{ example.title }}](#{{ column.name | lower }}){{ ", " if not loop.last else "" }}{% endfor %}_{% endif %}

{% endfor %}

{% for name, column in column_docs.columns.items() %}
### {{ name }}

{{ column.cls.__doc__ | cleandoc }}

{% if column.examples %}
#### Examples

{% for example in column.examples %}

<a id="{{ column.name | lower }}{{ loop.index }}"></a>
<details>
  <summary>{{ example.title }}</summary>

  {{ example.desc }}

  Template:
  ```
  {% if example.column_yaml %}
  {{- example.column_yaml -}}
  {% elif example.columns_yaml %}
  {{- example.columns_yaml -}}
  {% endif -%}
  ```

  Result:
  {{ example |  render_example }}

</details>

{% endfor %}
{% endif %}

---
{% endfor %}

## Targets

faux-data templates support the following `targets:`:

{% for target in targets -%}
- [{{ target[0] }}](#{{ target[0] | lower }})
{% endfor %}

{% for target in targets %}
### {{ target[0] }}

{{ target[1].__doc__ | cleandoc }}

{% endfor %}

## Usage

The library can be used in various ways
- via the faux cli
- as a library by importing it into your python project, instantiating templates and calling the `.generate()` or `.run()` methods on them
- running the code in a cloud function, passing a template to the cloud function at call time, or using a template stored in cloud storage

### Using the CLI

#### Configuration
To use Google Cloud targets do *one* of the following:
- ensure that the `GOOGLE_CLOUD_PROJECT` environment variable is set 
- set the `FAUXDATA_GCP_PROJECT_ID` environment variable
- place a toml file at `~/.fauxdata/config.toml` with the following contents:

```
gcp_project_id = "myproject"
```

---

### Using the Python Library

---

### Deploying as a Cloud Function

To deploy a cloud function

```
gcloud functions deploy faux-data \
  --region europe-west2 \
  --project XXX \
  --runtime python310 \
  --trigger-http \
  --set-env-vars='FAUXDATA_DEPLOYMENT_MODE=cloud_function,FAUXDATA_TEMPLATE_BUCKET=df2test,FAUXDATA_TEMPLATE_LOCATION=templates' \
  --entry-point generate

```
---

## Concepts

### Variables

You can specify variables in a template to make parts of it modifyable at runtime. A common use case for this is to control the number of rows of data generated as follows:

```
variables:
  row_count: 100
tables:
  - name: mytable
    rows: {{ '{{ row_count }}' }}
    columns:
      ...
```
By default the above will generate 100 rows, but when running the template you can specify row_count to override this number. For examples through the cli you might run `faux run mytemplate.yaml --row_count 40000`.

---

### Data Types and Output Types

---

### Using a CSV as the basis for a table

You may want to contain hardcoded data for some or all columns of a table. You can do this by specifying the path to the file as the `rows:` attribute. The path should be either a path relative to the template directory or an absolute or cloud storage path.

The following example will look for mytable.csv in the same directory as the template yaml file. This will work whether the template file is local or stored in cloud storage.

```
tables:
  - name: mytable
    rows: mytable.csv
    columns:
      ...
```

The following example, being an absolute pathm, will load the csv from cloud storage regardless of where the template yaml is loaded from.

```
tables:
  - name: mytable
    rows: gs://mybucket/templates/data/mytable.csv
    columns:
      ...
```
---
